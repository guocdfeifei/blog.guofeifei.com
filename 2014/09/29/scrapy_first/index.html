
 <!DOCTYPE HTML>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  
    <title>scrapy3入门简介，翻译Scrapy Tutorial | guofeifei&#39;s blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=3, minimum-scale=1">
    
    <meta name="author" content="guoff">
    
    <meta name="description" content="最终存放在博客上 www.guofeifei.com
翻译版本 0.14.4（当前最新0.24,因为ubuntu下能安装的最高版本是 0.14.4,所以）
原文地址
http://doc.scrapy.org/en/0.14/intro/tutorial.html
译文
Pay attention ">
    
    
    
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/pacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/pacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css" type="text/css">
</head>

  <body>
    <header>
      <div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.svg" alt="guofeifei&#39;s blog" title="guofeifei&#39;s blog"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="guofeifei&#39;s blog">guofeifei&#39;s blog</a></h1>
				<h2 class="blog-motto">Writing thinking doing</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
					<li>
					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="text" id="search" name="q" autocomplete="off" maxlength="20" placeholder="搜索" />
						<input type="hidden" name="q" value="site:www.guofeifei.com">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>

    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2014/09/29/scrapy_first/" title="scrapy3入门简介，翻译Scrapy Tutorial" itemprop="url">scrapy3入门简介，翻译Scrapy Tutorial</a>
  </h1>
  <p class="article-author">By
    
      <a href="http://www.guofeifei.com" title="guoff">guoff</a>
    </p>
  <p class="article-time">
    <time datetime="2014-09-29T15:16:47.000Z" itemprop="datePublished">2014-09-29</time>
    更新日期:<time datetime="2015-06-23T16:54:05.262Z" itemprop="dateModified">2015-06-24</time>
    
  </p>
</header>
	<div class="article-content">
		
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">文章目录</strong>
		<ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#What_just_happened_under_the_hood?"><span class="toc-number">1.</span> <span class="toc-text">What just happened under the hood?</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Extracting_Items"><span class="toc-number"></span> <span class="toc-text">Extracting Items</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Introduction_to_Selectors"><span class="toc-number">1.</span> <span class="toc-text">Introduction to Selectors</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Trying_Selectors_in_the_Shell"><span class="toc-number">2.</span> <span class="toc-text">Trying Selectors in the Shell</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Extracting_the_data"><span class="toc-number">3.</span> <span class="toc-text">Extracting the data</span></a></li></ol>
		</div>
		
		<p>最终存放在博客上 www.guofeifei.com</p>
<p>翻译版本 0.14.4（当前最新0.24,因为ubuntu下能安装的最高版本是 0.14.4,所以）</p>
<p>原文地址</p>
<p><a href="http://doc.scrapy.org/en/0.14/intro/tutorial.html" target="_blank" rel="external">http://doc.scrapy.org/en/0.14/intro/tutorial.html</a></p>
<p>译文</p>
<p>Pay attention to the lines containing <code>[dmoz]</code>, which corresponds to our spider. You can see a log line for each URL defined in <code>start_urls</code>. Because these URLs are the starting ones, they have no referrers, which is shown at the end of the log line, where it says <code>(referer: &lt;None&gt;)</code>.</p>
<p>重点关注含有dmoz的行，那是当前爬虫。你可以看到Start_urls中每个url的日志。因为是从这些urls开始的，所以在日志每行结尾都写着未引用。</p>
<p>But more interesting, as our <code>parse</code> method instructs, two files have been created: <em>Books</em> and <em>Resources</em>, with the content of both URLs.</p>
<p>更应该关注的是，在我们的parse方法的操作下，Books和Resources俩文件被创建，里面包含urls对应的内容。</p>
<h4 id="What_just_happened_under_the_hood?"><strong>What just happened under the hood?</strong></h4><p>Scrapy creates <code>scrapy.http.Request</code> objects for each URL in the <code>start_urls</code>attribute of the Spider, and assigns them the <code>parse</code> method of the spider as their callback function.</p>
<p>These Requests are scheduled, then executed, and <code>scrapy.http.Response</code>objects are returned and then fed back to the spider, through the <code>parse()</code>method.</p>
<p>在引擎下发生了什么？</p>
<p>scrapy为每个要爬的url创建了scrapy.http.Request对象，并且指定parse爬虫方法作为他们的回调函数。</p>
<p>这些请求预先设定好，当执行后，scrapy.http.Response对象通过parse方法被反馈给爬虫。</p>
<h3 id="Extracting_Items"><strong>Extracting Items</strong></h3><h4 id="Introduction_to_Selectors"><strong>Introduction to Selectors</strong></h4><p>There are several ways to extract data from web pages. Scrapy uses a mechanism based on XPath expressions called <em>XPath selectors</em>. For more information about selectors and other extraction mechanisms see the <em>XPath selectors documentation</em>.</p>
<p>Here are some examples of XPath expressions and their meanings:</p>
<ul>
<li><p><code>/html/head/title</code>: selects the <code>&lt;title&gt;</code> element, inside the <code>&lt;head&gt;</code> element of a HTML document</p>
</li>
<li><p><code>/html/head/title/text()</code>: selects the text inside the aforementioned<code>&lt;title&gt;</code> element.</p>
</li>
<li><p><code>//td</code>: selects all the <code>&lt;td&gt;</code> elements</p>
</li>
<li><p><code>//div[@class=&quot;mine&quot;]</code>: selects all <code>div</code> elements which contain an attribute<code>class=&quot;mine&quot;</code></p>
</li>
</ul>
<p>提取条目</p>
<p>介绍下选择器</p>
<p>这里有多种方式来从网页上提取数据。scrapy采用基于XPath表达式的被称为XPath选择器的机制。要想了解其更多，请看<em>XPath selectors documentation__。</em></p>
<p><em>这里有些例子及其含义</em></p>
<p><em>/html/head/title:<strong>选择</strong><title>element,<strong>在</strong>html<strong>里面的</strong><head>__标签内。</head></title></em></p>
<p><em>/html/head/title/text():<strong>选择</strong>title__元素里面的内容</em></p>
<p><em>//td<strong>：选择所有的</strong><td>__元素</td></em></p>
<p><em>//div[@class=”mine”]:<strong>选择所有含有</strong>class=”mine”<strong>属性的</strong>div__元素</em></p>
<p>These are just a couple of simple examples of what you can do with XPath, but XPath expressions are indeed much more powerful. To learn more about XPath we recommend this XPath tutorial.</p>
<p>For working with XPaths, Scrapy provides a <code>XPathSelector</code> class, which comes in two flavours, <code>HtmlXPathSelector</code> (for HTML data) and<code>XmlXPathSelector</code> (for XML data). In order to use them you must instantiate the desired class with a <code>Response</code> object.</p>
<p>You can see selectors as objects that represent nodes in the document structure. So, the first instantiated selectors are associated to the root node, or the entire document.</p>
<p>Selectors have three methods (click on the method to see the complete API documentation).</p>
<ul>
<li><p><code>select()</code>: returns a list of selectors, each of them representing the nodes selected by the xpath expression given as argument.</p>
</li>
<li><p><code>extract()</code>: returns a unicode string with<br> the data selected by the XPath selector.</p>
</li>
<li><p><code>re()</code>: returns a list of unicode strings extracted by applying the regular expression given as argument.</p>
</li>
<li></li>
</ul>
<p>上面仅仅是能用XPath做的一些简单例子，XPath表达式的确非常强大，想学习更多XPath，我们推荐教程this XPath tutorial.</p>
<p>为了用XPaths 工作，Scrapy提供了XPathSelector类，随之带来两大特性，HtmlXPathSelector(对于html)和XmlXPathSelector(对于xml)，为了使用他们，你必须实例化对象所需的响应。</p>
<p>显然选择器被作为节点和文档结构的标识。所以，第一个实例化的选择器可以被假设为跟节点或是整个文档。</p>
<p>选择器有三个方法（单击方法可查看详细api）</p>
<ul>
<li><p><code>select()</code>:返回一个选择器列表，每个返回值都是对应xpath表达式的对应的选择结果。</p>
</li>
<li><p><code>extract()</code>: 从XPath选择器返回一个统一编码的字符串。</p>
</li>
<li><code>re()</code>: 返回一个将统一编码的字符串作为参数正则表达式提取的列表。</li>
</ul>
<h4 id="Trying_Selectors_in_the_Shell"><strong>Trying Selectors in the Shell</strong></h4><p>To illustrate the use of Selectors we’re going to use the built-in <em>Scrapy shell</em>, which also requires IPython (an extended Python console) installed on your system.</p>
<p>To start a shell, you must go to the project’s top level directory and run:</p>
<p>在shell下练习选择器</p>
<p>为举例说明选择器，将用scrapy的shell平台，要求安装IPython（一个加强的python控制台）在你的系统中。</p>
<p>为了开始shell，你必须到达项目的顶目录，并执行：</p>
<pre><code>scrapy



shell



<span class="label">http:</span>//www.dmoz<span class="preprocessor">.org</span>/Computers/Programming/Languages/Python/Books/



下面请根据原文验证，经测试很爽。
</code></pre><h4 id="Extracting_the_data"><strong>Extracting the data</strong></h4><p>Now, let’s try to extract some real information from those pages.</p>
<p>You could type <code>response.body</code> in the console, and inspect the source code to figure out the XPaths you need to use. However, inspecting the raw HTML code there could become a very tedious task. To make this an easier task, you can use some Firefox extensions like Firebug. For more information see <em>Using Firebug for scraping</em> and <em>Using Firefox for scraping</em>.</p>
<p>After inspecting the page source, you’ll find that the web sites information is inside a <code>&lt;ul&gt;</code> element, in fact the <em>second</em> <code>&lt;ul&gt;</code> element.</p>
<p>So we can select each <code>&lt;li&gt;</code> element belonging to the sites list with this code:</p>
<pre><code>hxs.<span class="function"><span class="title">select</span><span class="params">(<span class="string">'//ul/li'</span>)</span></span>
</code></pre><p>And from them, the sites descriptions:</p>
<pre><code>hxs.<span class="function"><span class="title">select</span><span class="params">(<span class="string">'//ul/li/text()'</span>)</span></span>.<span class="function"><span class="title">extract</span><span class="params">()</span></span>
</code></pre><p>The sites titles:</p>
<pre><code>hxs.<span class="function"><span class="title">select</span><span class="params">(<span class="string">'//ul/li/a/text()'</span>)</span></span>.<span class="function"><span class="title">extract</span><span class="params">()</span></span>
</code></pre><p>And the sites links:</p>
<pre><code>hxs.<span class="function"><span class="title">select</span><span class="params">(<span class="string">'//ul/li/a/@href'</span>)</span></span>.<span class="function"><span class="title">extract</span><span class="params">()</span></span>
</code></pre><p>As we said before, each <code>select()</code> call returns a list of selectors, so we can concatenate further <code>select()</code> calls to dig deeper into a node. We are going to use that property here, so:</p>
<p>提取数据</p>
<p>现在正式开始在这些页面上提取有用的信息。</p>
<p>你可以在控制台键入response.body，查看源码，根据所用输入XPaths。然后，检查原始html代码可能是一件非常乏味的事儿了。为了让自己爽，你可以用一些火狐的扩展，像firebug。看 <em>Using Firebug for scraping</em> 和 <em>Using Firefox for scraping__获取更多知识</em>.</p>
<p>After inspecting the page source, you’ll find that the web sites information is inside a <ul>element, in fact the second <ul> element.</ul></ul></p>
<p>So we can select each <li> element belonging to the sites list with this code:</li></p>
<p>hxs.select(‘//ul/li’)</p>
<p>And from them, the sites descriptions:</p>
<p>hxs.select(‘//ul/li/text()’).extract()</p>
<p>The sites titles:</p>
<p>hxs.select(‘//ul/li/a/text()’).extract()</p>
<p>And the sites links:</p>
<p>hxs.select(‘//ul/li/a/@href’).extract()</p>
<p>As we said before, each select() call returns a list of selectors, so we can concatenate furtherselect() calls to dig deeper into a node. We are going to use that property here, so:</p>
<p>sites = hxs.select(‘//ul/li’)</p>
<p>for site in sites:</p>
<p>title = site.select(‘a/text()’).extract()</p>
<p>link = site.select(‘a/@href’).extract()</p>
<p>desc = site.select(‘text()’).extract()</p>
<p>print title, link, desc</p>
<p>Now try crawling the dmoz.org domain again and you’ll see sites being printed in your output, run:</p>
<p>scrapy crawl dmoz</p>
<p>Using our item</p>
<p>Item objects are custom python dicts; you can access the values of their fields (attributes of the class we defined earlier) using the standard dict syntax like:</p>
<blockquote>
<blockquote>
<blockquote>
<p>item = DmozItem()</p>
<p>item[‘title’] = ‘Example title’</p>
<p>item[‘title’]</p>
</blockquote>
</blockquote>
</blockquote>
<p>‘Example title’</p>
<p>Spiders are expected to return their scraped data inside Item objects. So, in order to returnthe data we’ve scraped so far, the final code for our Spider would be like this:</p>
<p>from scrapy.spider import BaseSpider</p>
<p>from scrapy.selector import HtmlXPathSelector</p>
<p>from tutorial.items import DmozItem</p>
<p>class DmozSpider(BaseSpider):</p>
<p>name = “dmoz”</p>
<p>allowed_domains = [“dmoz.org”]</p>
<p>start_urls = [</p>
<p>“<a href="http://www.dmoz.org/Computers/Programming/Languages/Python/Books/" target="_blank" rel="external">http://www.dmoz.org/Computers/Programming/Languages/Python/Books/</a>“,</p>
<p>“<a href="http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/" target="_blank" rel="external">http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/</a>“</p>
<p>]</p>
<p>def parse(self, response):</p>
<p>hxs = HtmlXPathSelector(response)</p>
<p>sites = hxs.select(‘//ul/li’)</p>
<p>items = []</p>
<p>for site in sites:</p>
<p>item = DmozItem()</p>
<p>item[‘title’] = site.select(‘a/text()’).extract()</p>
<p>item[‘link’] = site.select(‘a/@href’).extract()</p>
<p>item[‘desc’] = site.select(‘text()’).extract()</p>
<p>items.append(item)</p>
<p>return items</p>
<p>Note</p>
<p>You can find a fully-functional variant of this spider in the dirbot project available at<a href="https://github.com/scrapy/dirbot" target="_blank" rel="external">https://github.com/scrapy/dirbot</a></p>
<p>Now doing a crawl on the dmoz.org domain yields DmozItem‘s:</p>
<p>[dmoz] DEBUG: Scraped from <200 http:="" www.dmoz.org="" computers="" programming="" languages="" python="" books=""></200></p>
<p>{‘desc’: [u’ - By David Mertz; Addison Wesley. Book in progress, full text, ASCII format. Asks for feedback. [author website, Gnosis Software, Inc.\n],</p>
<p>‘link’: [u’<a href="http://gnosis.cx/TPiP/" target="_blank" rel="external">http://gnosis.cx/TPiP/</a>‘],</p>
<p>‘title’: [u’Text Processing in Python’]}</p>
<p>[dmoz] DEBUG: Scraped from <200 http:="" www.dmoz.org="" computers="" programming="" languages="" python="" books=""></200></p>
<p>{‘desc’: [u’ - By Sean McGrath; Prentice Hall PTR, 2000, ISBN 0130211192, has CD-ROM. Methods to build XML applications fast, Python tutorial, DOM and SAX, new Pyxie open source XML processing library. [Prentice Hall PTR]\n’],</p>
<p>‘link’: [u’<a href="http://www.informit.com/store/product.aspx?isbn=0130211192" target="_blank" rel="external">http://www.informit.com/store/product.aspx?isbn=0130211192</a>‘],</p>
<p>‘title’: [u’XML Processing with Python’]}</p>
<p>Storing the scraped data</p>
<p>The simplest way to store the scraped data is by using the Feed exports, with the following command:</p>
<p>scrapy crawl dmoz -o items.json -t json</p>
<p>That will generate a items.json file containing all scraped items, serialized in JSON.</p>
<p>In small projects (like the one in this tutorial), that should be enough. However, if you want to perform more complex things with the scraped items, you can write an Item Pipeline. As with Items, a placeholder file for Item Pipelines has been set up for you when the project is created, intutorial/pipelines.py. Though you don’t need to implement any item pipeline if you just want to store the scraped items.</p>
<p>Next steps</p>
<p>This tutorial covers only the basics of Scrapy, but there’s a lot of other features not mentioned here. We recommend you continue by playing with an example project (see Examples), and then continue with the section Basic concepts.</p>
  
	</div>
		<footer class="article-footer clearfix">

  <div class="article-tags">
  
  <span></span> <a href="/tags/python/">python</a><a href="/tags/scrapy/">scrapy</a>
  </div>


<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/python/">python</a>
</div>



<div class="article-share" id="share">

  <div data-url="http://www.guofeifei.com/2014/09/29/scrapy_first/" data-title="scrapy3入门简介，翻译Scrapy Tutorial | guofeifei&#39;s blog" data-tsina="null" class="share clearfix">
  </div>

</div>
</footer>   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2014/10/05/ubuntumysql/" title="ubuntu上mysql的安装以及基本用法">
  <strong>PREVIOUS:</strong><br/>
  <span>
  ubuntu上mysql的安装以及基本用法</span>
</a>
</div>


<div class="next">
<a href="/2014/09/24/vim/"  title="vi命令用法，常用，字典">
 <strong>NEXT:</strong><br/> 
 <span>vi命令用法，常用，字典
</span>
</a>
</div>

</nav>

	
<section class="comment">
	<div class="ds-thread"></div>
</section>

</div>  
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">文章目录</strong>
  <ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#What_just_happened_under_the_hood?"><span class="toc-number">1.</span> <span class="toc-text">What just happened under the hood?</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Extracting_Items"><span class="toc-number"></span> <span class="toc-text">Extracting Items</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Introduction_to_Selectors"><span class="toc-number">1.</span> <span class="toc-text">Introduction to Selectors</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Trying_Selectors_in_the_Shell"><span class="toc-number">2.</span> <span class="toc-text">Trying Selectors in the Shell</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Extracting_the_data"><span class="toc-number">3.</span> <span class="toc-text">Extracting the data</span></a></li></ol>
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  
<div class="categorieslist">
	<p class="asidetitle">分类</p>
		<ul>
		
			<li><a href="/categories/Java/" title="Java">Java<sup>3</sup></a></li>
		
			<li><a href="/categories/c-c/" title="c/c++">c/c++<sup>3</sup></a></li>
		
			<li><a href="/categories/django/" title="django">django<sup>13</sup></a></li>
		
			<li><a href="/categories/web/html5/" title="html5">html5<sup>1</sup></a></li>
		
			<li><a href="/categories/mezzanine/" title="mezzanine">mezzanine<sup>1</sup></a></li>
		
			<li><a href="/categories/mysql/" title="mysql">mysql<sup>5</sup></a></li>
		
			<li><a href="/categories/oracle/" title="oracle">oracle<sup>26</sup></a></li>
		
			<li><a href="/categories/python/" title="python">python<sup>9</sup></a></li>
		
			<li><a href="/categories/ubuntu/" title="ubuntu">ubuntu<sup>4</sup></a></li>
		
			<li><a href="/categories/web/" title="web">web<sup>8</sup></a></li>
		
			<li><a href="/categories/低落/" title="低落">低落<sup>1</sup></a></li>
		
			<li><a href="/categories/django/兴奋的事儿/" title="兴奋的事儿">兴奋的事儿<sup>3</sup></a></li>
		
			<li><a href="/categories/兴奋的事儿/" title="兴奋的事儿">兴奋的事儿<sup>4</sup></a></li>
		
			<li><a href="/categories/喜欢/" title="喜欢">喜欢<sup>1</sup></a></li>
		
			<li><a href="/categories/工作随感/" title="工作随感">工作随感<sup>4</sup></a></li>
		
			<li><a href="/categories/工具/" title="工具">工具<sup>3</sup></a></li>
		
			<li><a href="/categories/待办/" title="待办">待办<sup>10</sup></a></li>
		
			<li><a href="/categories/我是大厨/" title="我是大厨">我是大厨<sup>4</sup></a></li>
		
			<li><a href="/categories/概念/" title="概念">概念<sup>1</sup></a></li>
		
			<li><a href="/categories/生活点滴/" title="生活点滴">生活点滴<sup>6</sup></a></li>
		
			<li><a href="/categories/翻译/" title="翻译">翻译<sup>1</sup></a></li>
		
		</ul>
</div>


  
<div class="tagslist">
	<p class="asidetitle">标签</p>
		<ul class="clearfix">
		
			<li><a href="/tags/C/" title="C++">C++<sup>1</sup></a></li>
		
			<li><a href="/tags/CKEDITOR/" title="CKEDITOR">CKEDITOR<sup>1</sup></a></li>
		
			<li><a href="/tags/JAVA/" title="JAVA">JAVA<sup>1</sup></a></li>
		
			<li><a href="/tags/Linux/" title="Linux">Linux<sup>1</sup></a></li>
		
			<li><a href="/tags/Oracle/" title="Oracle">Oracle<sup>1</sup></a></li>
		
			<li><a href="/tags/WdatePicker/" title="WdatePicker">WdatePicker<sup>1</sup></a></li>
		
			<li><a href="/tags/bootstrap/" title="bootstrap">bootstrap<sup>1</sup></a></li>
		
			<li><a href="/tags/c/" title="c">c<sup>3</sup></a></li>
		
			<li><a href="/tags/c/" title="c++">c++<sup>1</sup></a></li>
		
			<li><a href="/tags/chrome/" title="chrome">chrome<sup>1</sup></a></li>
		
			<li><a href="/tags/createjs/" title="createjs">createjs<sup>1</sup></a></li>
		
			<li><a href="/tags/crt/" title="crt">crt<sup>1</sup></a></li>
		
			<li><a href="/tags/css3/" title="css3">css3<sup>1</sup></a></li>
		
			<li><a href="/tags/django/" title="django">django<sup>7</sup></a></li>
		
			<li><a href="/tags/django-lfs/" title="django-lfs">django-lfs<sup>1</sup></a></li>
		
			<li><a href="/tags/eclipse/" title="eclipse">eclipse<sup>1</sup></a></li>
		
			<li><a href="/tags/error/" title="error">error<sup>4</sup></a></li>
		
			<li><a href="/tags/fiddler/" title="fiddler">fiddler<sup>1</sup></a></li>
		
			<li><a href="/tags/ftp/" title="ftp">ftp<sup>1</sup></a></li>
		
			<li><a href="/tags/geany/" title="geany">geany<sup>1</sup></a></li>
		
		</ul>
</div>


  <div class="rsspart">
	<a href="null" target="_blank" title="rss">RSS 订阅</a>
</div>

</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	
	<div class="social-font clearfix">
		
		
		
		
		
	</div>
		<p class="copyright">Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/A-limon/pacman" target="_blank" title="Pacman">Pacman</a> © 2015 
		
		<a href="http://www.guofeifei.com" target="_blank" title="guoff">guoff</a>
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.1.0.min.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else
    {
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      h  = $('article h2')
      ah = $('article h2'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  if(ah.length==0){
    t.css('display','none');
  }else{
    c.click(function(){
      ta.css('display', 'block').addClass('fadeIn');
    });
    o.click(function(){
      ta.css('display', 'none');
    });
    $(window).scroll(function(){
      ta.css("top",Math.max(140,320-$(this).scrollTop()));
    });
  };
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina');
  var html = [
  '<a href="#" class="overlay" id="qrcode"></a>',
  '<div class="qrcode clearfix"><span>扫描二维码分享到微信朋友圈</span><a class="qrclose" href="#share"></a><strong>Loading...Please wait</strong><img id="qrcode-pic" data-src="http://s.jiathis.com/qrcode.php?url=' + encodedUrl + '"/></div>',
  '<a href="#textlogo" class="article-back-to-top" title="Top"></a>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="QRcode"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="Weibo"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);
  $('.article-share-qrcode').click(function(){
    var imgSrc = $('#qrcode-pic').attr('data-src');
    $('#qrcode-pic').attr('src', imgSrc);
    $('#qrcode-pic').load(function(){
        $('.qrcode strong').text(' ');
    });
  });
});     
</script>


<script type="text/javascript">
  var duoshuoQuery = {short_name:"git_guoff"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
    || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
</script> 





  </body>
</html>
